{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OAE: MNIST\n",
    "\n",
    "## Evaluations - Numerics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /DATA/home/muha/wrapped_code/ornstein_auto_encoder/ornstein_auto_encoder/utils.py:11: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import json\n",
    "import copy\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='0'\n",
    "import tensorflow as tf\n",
    "\n",
    "# seed_value = 202\n",
    "seed_value = 1234\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "random.seed(seed_value)\n",
    "np.random.seed(seed_value)\n",
    "tf.set_random_seed(seed_value)\n",
    "\n",
    "from keras.models import model_from_yaml, load_model, Model\n",
    "from keras.layers import Input, Lambda\n",
    "from keras.utils import to_categorical\n",
    "import keras.backend as k\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = True\n",
    "k.set_session(tf.Session(config=config))\n",
    "\n",
    "sys.path.append('/'.join(os.getcwd().split('/')))\n",
    "from ornstein_auto_encoder import configuration\n",
    "from ornstein_auto_encoder import readers\n",
    "from ornstein_auto_encoder import samplers\n",
    "from ornstein_auto_encoder import build_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logging.basicConfig(format = '[%(name)-8s|%(levelname)s|%(filename)s:%(lineno)s] %(message)s',\n",
    "                    level=logging.INFO)\n",
    "log = logging.getLogger()\n",
    "logging.getLogger(\"PIL\").setLevel(logging.CRITICAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[tensorflow|WARNING|deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[tensorflow|WARNING|module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mnist_classifier = load_model('mnist_classifier.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_path = 'mnist_pretrained/mnist_imbalance_psoae'\n",
    "models_aka = 'PSOAE'\n",
    "path_info_config = \"configurations/mnist/psoae_path_info.cfg\"\n",
    "network_info_config = \"configurations/mnist/psoae_network_info.cfg\"\n",
    "feature_b = False\n",
    "\n",
    "config_data = configuration.Configurator(path_info_config, log, verbose=False)\n",
    "config_data.set_config_map(config_data.get_section_map())\n",
    "config_network = configuration.Configurator(network_info_config, log, verbose=False)\n",
    "config_network.set_config_map(config_network.get_section_map())\n",
    "path_info = config_data.get_config_map()\n",
    "network_info = config_network.get_config_map()\n",
    "\n",
    "# Reader\n",
    "reader_class = getattr(readers, network_info['model_info']['reader_class'].strip())  \n",
    "reader = reader_class(log, path_info, network_info, verbose=False)\n",
    "\n",
    "image_shape = reader.img_shape\n",
    "img_pair1 = Input(shape=image_shape, name='image_input_1', dtype='float32')\n",
    "img_pair2 = Input(shape=image_shape, name='image_input_2', dtype='float32')\n",
    "ms_ssim = Lambda(lambda x: tf.image.ssim_multiscale(x[0], x[1], 1), name='ms_ssim')([img_pair1, img_pair2])\n",
    "ms_ssim_model = Model([img_pair1, img_pair2], ms_ssim)\n",
    "\n",
    "ssim = Lambda(lambda x: tf.image.ssim(x[0], x[1], 1), name='ssim')([img_pair1, img_pair2])\n",
    "ssim_model = Model([img_pair1, img_pair2], ssim)\n",
    "\n",
    "def get_ssim(class_images, size=50):\n",
    "    pair1 = np.random.choice(np.arange(class_images.shape[0]), size)\n",
    "    pair2 = np.random.choice(np.setdiff1d(np.arange(class_images.shape[0]), pair1, assume_unique=True), size)\n",
    "    return ssim_model.predict_on_batch([class_images[pair1], class_images[pair2]])\n",
    "\n",
    "def get_ms_ssim(class_images, size=50):\n",
    "    pair1 = np.random.choice(np.arange(class_images.shape[0]), size)\n",
    "    pair2 = np.random.choice(np.setdiff1d(np.arange(class_images.shape[0]), pair1, assume_unique=True), size)\n",
    "    return ms_ssim_model.predict_on_batch([class_images[pair1], class_images[pair2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_numerics(model_path, model_aka, \n",
    "                 path_info_config = \"configurations/mnist/psoae_path_info.cfg\",\n",
    "                 network_info_config = \"configurations/mnist/psoae_network_info.cfg\", feature_b=False):\n",
    "    config_data = configuration.Configurator(path_info_config, log, verbose=False)\n",
    "    config_data.set_config_map(config_data.get_section_map())\n",
    "    config_network = configuration.Configurator(network_info_config, log, verbose=False)\n",
    "    config_network.set_config_map(config_network.get_section_map())\n",
    "    path_info = config_data.get_config_map()\n",
    "    network_info = config_network.get_config_map()\n",
    "\n",
    "    architecture = path_info['model_info']['model_architecture']\n",
    "\n",
    "    ### Bulid network ####################################################################################\n",
    "    network_class = getattr(build_network, network_info['model_info']['network_class'].strip())  \n",
    "    network = network_class(log, path_info, network_info, n_label=reader.get_n_label())\n",
    "    network.build_model('./%s/%s' % (model_path,  path_info['model_info']['model_architecture']), verbose=False)\n",
    "    network.load(model_path)\n",
    "\n",
    "    # Training\n",
    "    train_tot_idxs_path = os.path.join(model_path, path_info['model_info']['train_tot_idxs'])\n",
    "    test_tot_idxs_path = os.path.join(model_path, path_info['model_info']['test_tot_idxs'])\n",
    "    train_idx = np.load(train_tot_idxs_path)\n",
    "    test_idx = np.load(test_tot_idxs_path)\n",
    "\n",
    "    ### Sampler ##########################################################################################\n",
    "    log.info('-----------------------------------------------------------------')\n",
    "    # Training data sampler\n",
    "    log.info('Construct training data sampler')\n",
    "    train_sampler_class = getattr(samplers, network_info['training_info']['sampler_class'].strip())\n",
    "    train_sampler = train_sampler_class(log, train_idx, reader, network_info['training_info'], verbose=True)\n",
    "\n",
    "    # Test data sampler\n",
    "    log.info('Construct test data sampler')\n",
    "    validation_sampler_class = getattr(samplers, network_info['validation_info']['sampler_class'].strip())\n",
    "    test_sampler = validation_sampler_class(log, test_idx, reader, network_info['validation_info'], verbose=True)\n",
    "\n",
    "    tot_original_accuracy = []\n",
    "    tot_original_ssim_mean = []\n",
    "    tot_sharpness_original = []\n",
    "\n",
    "    tot_reconstruction = []\n",
    "    tot_accuracy = []\n",
    "    tot_gen_ssim_mean = []\n",
    "    tot_sharpness_gen = []\n",
    "\n",
    "    tot_one_shot_accuracy = []\n",
    "    tot_one_shot_gen_ssim_mean = []\n",
    "    tot_one_shot_sharpness_gen = []\n",
    "\n",
    "    for nrepeat in range(10):\n",
    "        log.info('------------------ %d repeat ------------------------------------------------------' % nrepeat)\n",
    "        current_idxs = np.random.choice(test_idx, 1000)\n",
    "        x, y = test_sampler.reader.get_batch(current_idxs)\n",
    "        y_table = pd.Series(y)\n",
    "        y_index = pd.Index(y)\n",
    "        y_class = np.sort(y_table.unique())\n",
    "        y_table = pd.Series(y)\n",
    "        y_counts = y_table.value_counts()\n",
    "        log.info('-------------------------------------------------')\n",
    "        log.info('Images per Class')\n",
    "        log.info('\\n%s', y_counts)\n",
    "        log.info('-------------------------------------------------')\n",
    "        log.info('Summary')\n",
    "        log.info('\\n%s', y_counts.describe())\n",
    "        log.info('-------------------------------------------------')\n",
    "        wx, wy = network.main_sampler(x,y)\n",
    "        try:\n",
    "            if len(x.shape) == 4: real_img = x\n",
    "        except: real_img = x[0]\n",
    "\n",
    "        picked_one_shot_idxs_per_class = [np.random.choice(np.where(y == cls)[0], 1)[0] for i, cls in enumerate(y_class)]\n",
    "        repeated = 100\n",
    "        esp = 1.\n",
    "        gen_y_class = np.repeat(y_class, repeated, axis=0)\n",
    "\n",
    "        if ('randomintercept' in network_info['model_info']['network_class'].lower() or \\\n",
    "            'productspace' in network_info['model_info']['network_class'].lower()):\n",
    "            recon_x = network.ae_model.predict(wx[:-1], batch_size=100, verbose=0)\n",
    "        elif ('conditional' in network_info['model_info']['network_class'].lower()):\n",
    "            recon_x = network.ae_model.predict(wx, batch_size=100, verbose=0)\n",
    "        else:\n",
    "            recon_x = network.ae_model.predict(wx[:1], batch_size=100, verbose=0)\n",
    "        if 'randomintercept' in network_info['model_info']['network_class'].lower():\n",
    "            b_sd = float(network_info['model_info']['b_sd'])\n",
    "            estimate_b, fake_noise = network.encoder_model.predict(x, batch_size=100)\n",
    "            new_b = np.random.multivariate_normal(np.zeros(network.get_z_dim()), \n",
    "                                                  b_sd**2.*np.identity(network.get_z_dim()), \n",
    "                                                  y_class.shape[0]).astype(np.float32)\n",
    "            b = np.array([np.mean(estimate_b[np.random.choice(np.where(y==cls)[0],5)], axis=0) for cls in y_class])\n",
    "            one_shot_b = np.array([estimate_b[picked_one_shot_idxs_per_class[i]] for i, cls in enumerate(y_class)])\n",
    "            fake_latent = estimate_b + fake_noise\n",
    "        elif 'productspace' in network_info['model_info']['network_class'].lower():\n",
    "            if feature_b: img, feature, clss, b_noise = wx\n",
    "            else: img, clss, b_noise = wx\n",
    "            b_sd = float(network_info['model_info']['b_sd'])\n",
    "\n",
    "            if feature_b:\n",
    "                sample_b, b_given_x, estimate_b  = network.encoder_b_model.predict_on_batch([feature, clss])\n",
    "            else:\n",
    "                    sample_b, b_given_x, estimate_b  = network.encoder_b_model.predict_on_batch([img, clss])\n",
    "            b = np.array([np.mean(estimate_b[np.random.choice(np.where(y==cls)[0],5)], axis=0) for cls in y_class])\n",
    "            fake_noise = network.encoder_e_model.predict(wx[:-1], batch_size=100)\n",
    "            new_b = np.random.multivariate_normal(np.zeros(b.shape[-1]), \n",
    "                                                  b_sd**2.*np.identity(b.shape[-1]), \n",
    "                                                  y_class.shape[0]).astype(np.float32)\n",
    "            one_shot_b = np.array([estimate_b[picked_one_shot_idxs_per_class[i]] for i, cls in enumerate(y_class)])\n",
    "        else:\n",
    "            fake_latent = network.encoder_model.predict(x, batch_size=100)\n",
    "            fake_noise = fake_latent\n",
    "\n",
    "        mean = np.zeros(fake_noise.shape[-1])\n",
    "        cov = float(network_info['model_info']['e_sd'])**2.*np.identity(fake_noise.shape[-1])\n",
    "        true_noise = np.random.multivariate_normal(mean,cov,y.shape[0]).astype(np.float32)\n",
    "        mean = np.zeros(fake_noise.shape[-1])\n",
    "        cov = esp*np.identity(fake_noise.shape[-1])\n",
    "        noise = np.random.multivariate_normal(mean,cov,y_class.shape[0]*repeated).astype(np.float32)\n",
    "\n",
    "        if 'randomintercept' in network_info['model_info']['network_class'].lower():\n",
    "            generated_images = network.decoder_model.predict(noise + np.repeat(b, repeated, axis=0),  batch_size=100)\n",
    "            one_shot_generated_images = network.decoder_model.predict(noise + np.repeat(one_shot_b, repeated, axis=0), batch_size=100)\n",
    "        elif 'productspace' in network_info['model_info']['network_class'].lower():\n",
    "            generated_images = network.decoder_model.predict(np.concatenate([np.repeat(b, repeated, axis=0), noise], axis=-1),\n",
    "                                                             batch_size=100)\n",
    "            one_shot_generated_images = network.decoder_model.predict(np.concatenate([np.repeat(one_shot_b, repeated, axis=0), noise], axis=-1),\n",
    "                                                                      batch_size=100)\n",
    "        elif 'conditional' in network_info['model_info']['network_class'].lower():\n",
    "            generated_images = network.decoder_model.predict([noise, to_categorical(gen_y_class, reader.get_n_label())], batch_size=100)\n",
    "        else:\n",
    "            generated_images = network.decoder_model.predict(noise, batch_size=100)\n",
    "\n",
    "        numeric_dict = {}\n",
    "        original_clssifier_loss, original_classifier_accuracy = mnist_classifier.evaluate(x, \n",
    "                                                                                          to_categorical(y, \n",
    "                                                                                                         num_classes=y_class.shape[0]), verbose=0)\n",
    "        numeric_dict['original_accuracy'] = original_classifier_accuracy\n",
    "\n",
    "        clssifier_loss, classifier_accuracy = mnist_classifier.evaluate(generated_images, \n",
    "                                                                        to_categorical(gen_y_class, num_classes=y_class.shape[0]), verbose=0)\n",
    "        numeric_dict['accuracy'] = classifier_accuracy\n",
    "\n",
    "        if 'oae' in network_info['model_info']['network_class'].lower():\n",
    "            one_shot_clssifier_loss, one_shot_classifier_accuracy = mnist_classifier.evaluate(one_shot_generated_images, \n",
    "                                                                                              to_categorical(gen_y_class, \n",
    "                                                                                                             num_classes=y_class.shape[0]), \n",
    "                                                                                              verbose=0)\n",
    "            numeric_dict['one_shot_accuracy'] = one_shot_classifier_accuracy\n",
    "\n",
    "        origin_sharpness = np.min(network.blurr_model.predict(real_img, batch_size=100))\n",
    "        gen_sharpness = np.min(network.blurr_model.predict(generated_images,batch_size=100))\n",
    "        numeric_dict['sharpness_original'] = origin_sharpness\n",
    "        numeric_dict['sharpness_gen'] = gen_sharpness\n",
    "        numeric_dict['original_ssim_mean'] = np.mean([np.mean(get_ssim(real_img[y==cls])) for cls in y_class])\n",
    "        numeric_dict['gen_ssim_mean'] = np.mean([np.mean(get_ssim(generated_images[gen_y_class==cls], 10)) for cls in y_class])\n",
    "\n",
    "        if 'oae' in network_info['model_info']['network_class'].lower():\n",
    "            one_shot_gen_sharpness = np.min(network.blurr_model.predict(one_shot_generated_images, batch_size=100))\n",
    "            numeric_dict['sharpness_one_shot_gen'] = one_shot_gen_sharpness\n",
    "            numeric_dict['one_shot_gen_ssim_mean'] = np.mean([np.mean(get_ssim(one_shot_generated_images[gen_y_class==cls], 10)) for cls in y_class])\n",
    "        \n",
    "        log.info(numeric_dict)\n",
    "\n",
    "        tot_original_accuracy.append(numeric_dict['original_accuracy'])\n",
    "        tot_original_ssim_mean.append(numeric_dict['original_ssim_mean'])\n",
    "        tot_sharpness_original.append(numeric_dict['sharpness_original'])\n",
    "\n",
    "        tot_accuracy.append(numeric_dict['accuracy'])\n",
    "        tot_gen_ssim_mean.append(numeric_dict['gen_ssim_mean'])\n",
    "        tot_sharpness_gen.append(numeric_dict['sharpness_gen'])\n",
    "\n",
    "        if 'oae' in network_info['model_info']['network_class'].lower():\n",
    "            tot_one_shot_accuracy.append(numeric_dict['one_shot_accuracy'])\n",
    "            tot_one_shot_gen_ssim_mean.append(numeric_dict['one_shot_gen_ssim_mean'])\n",
    "            tot_one_shot_sharpness_gen.append(numeric_dict['sharpness_one_shot_gen'])\n",
    "    \n",
    "    log.info('-----------------------------------------------------------------')\n",
    "    log.info('Results of %s' % (model_aka))\n",
    "    log.info('-----------------------------------------------------------------')\n",
    "    log.info('Original accuracy: %.3f (\\pm %.3f)' % (np.mean(tot_original_accuracy), np.std(tot_original_accuracy)))\n",
    "    log.info('Original_ssim_mean: %.3f (\\pm %.3f)' % (np.mean(tot_original_ssim_mean), np.std(tot_original_ssim_mean)))\n",
    "    log.info('Original_sharpness: %.3f (\\pm %.3f)' % (np.mean(tot_sharpness_original), np.std(tot_sharpness_original)))\n",
    "\n",
    "    log.info('Accuracy: %.3f (\\pm %.3f)' % (np.mean(tot_accuracy), np.std(tot_accuracy)))\n",
    "    log.info('Ssim_mean: %.3f (\\pm %.3f)' % (np.mean(tot_gen_ssim_mean), np.std(tot_gen_ssim_mean)))\n",
    "    log.info('Sharpness: %.3f (\\pm %.3f)' % (np.mean(tot_sharpness_gen), np.std(tot_sharpness_gen)))\n",
    "\n",
    "    if 'oae' in network_info['model_info']['network_class'].lower():\n",
    "        log.info('One-shot Accuracy: %.3f (\\pm %.3f)' % (np.mean(tot_one_shot_accuracy), np.std(tot_one_shot_accuracy)))\n",
    "        log.info('One-shot Ssim_mean: %.3f (\\pm %.3f)' % (np.mean(tot_one_shot_gen_ssim_mean), np.std(tot_one_shot_gen_ssim_mean)))\n",
    "        log.info('One-shot Sharpness: %.3f (\\pm %.3f)' % (np.mean(tot_one_shot_sharpness_gen), np.std(tot_one_shot_sharpness_gen)))\n",
    "#         tot_numerics = [\n",
    "#             tot_original_accuracy,\n",
    "#             tot_original_ssim_mean,\n",
    "#             tot_sharpness_original,\n",
    "#             tot_reconstruction,\n",
    "#             tot_accuracy,\n",
    "#             tot_gen_ssim_mean,\n",
    "#             tot_sharpness_gen,\n",
    "#             tot_one_shot_accuracy,\n",
    "#             tot_one_shot_gen_ssim_mean,\n",
    "#             tot_one_shot_sharpness_gen\n",
    "#         ]\n",
    "#     else:\n",
    "#         tot_numerics = [\n",
    "#             tot_original_accuracy,\n",
    "#             tot_original_ssim_mean,\n",
    "#             tot_sharpness_original,\n",
    "#             tot_reconstruction,\n",
    "#             tot_accuracy,\n",
    "#             tot_gen_ssim_mean,\n",
    "#             tot_sharpness_gen\n",
    "#         ]\n",
    "\n",
    "\n",
    "#     np.save('./analysis/numerics_%s.npy' % model_aka, np.array(tot_numerics))\n",
    "    log.info('-----------------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[tensorflow|WARNING|deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /DATA/home/muha/wrapped_code/ornstein_auto_encoder/ornstein_auto_encoder/ops.py:300: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[tensorflow|WARNING|deprecation.py:506] From /DATA/home/muha/wrapped_code/ornstein_auto_encoder/ornstein_auto_encoder/ops.py:300: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /DATA/home/muha/wrapped_code/ornstein_auto_encoder/ornstein_auto_encoder/ops.py:352: The name tf.is_nan is deprecated. Please use tf.math.is_nan instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[tensorflow|WARNING|module_wrapper.py:139] From /DATA/home/muha/wrapped_code/ornstein_auto_encoder/ornstein_auto_encoder/ops.py:352: The name tf.is_nan is deprecated. Please use tf.math.is_nan instead.\n",
      "\n",
      "[root    |INFO|build_network.py:179] Training using single GPU or CPU\n",
      "/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py:341: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n",
      "[root    |INFO|build_network.py:197] Start models compile.\n",
      "[root    |INFO|build_network.py:388] Loaded WAE model\n",
      "[root    |INFO|layer_utils.py:112] Model: \"main_model\"\n",
      "[root    |INFO|layer_utils.py:113] ________________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "[root    |INFO|layer_utils.py:110] Layer (type)                                                      Output Shape                                Param #                 Connected to                                                      \n",
      "[root    |INFO|layer_utils.py:115] ========================================================================================================================================================================================================\n",
      "[root    |INFO|layer_utils.py:110] real_image_input (InputLayer)                                     (None, 28, 28, 1)                           0                                                                                         \n",
      "[root    |INFO|layer_utils.py:177] ________________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "[root    |INFO|layer_utils.py:110] class_info_input (InputLayer)                                     (None, 1)                                   0                                                                                         \n",
      "[root    |INFO|layer_utils.py:177] ________________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "[root    |INFO|layer_utils.py:110] encoder_b_model (Model)                                           [(None, 8), (None, 8), (None, 8)]           866496                  real_image_input[0][0]                                            \n",
      "[root    |INFO|layer_utils.py:110]                                                                                                                                       class_info_input[0][0]                                            \n",
      "[root    |INFO|layer_utils.py:177] ________________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "[root    |INFO|layer_utils.py:110] encoder_e_model (Model)                                           (None, 8)                                   869360                  real_image_input[0][0]                                            \n",
      "[root    |INFO|layer_utils.py:110]                                                                                                                                       class_info_input[0][0]                                            \n",
      "[root    |INFO|layer_utils.py:177] ________________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "[root    |INFO|layer_utils.py:110] encoder_z_model (Model)                                           (None, 16)                                  0                       encoder_b_model[1][0]                                             \n",
      "[root    |INFO|layer_utils.py:110]                                                                                                                                       encoder_e_model[1][0]                                             \n",
      "[root    |INFO|layer_utils.py:177] ________________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "[root    |INFO|layer_utils.py:110] decoder (Model)                                                   (None, 28, 28, 1)                           279617                  encoder_z_model[1][0]                                             \n",
      "[root    |INFO|layer_utils.py:177] ________________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "[root    |INFO|layer_utils.py:110] discriminator_e (Model)                                           (None, 1)                                   17281                   encoder_e_model[1][0]                                             \n",
      "[root    |INFO|layer_utils.py:177] ________________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "[root    |INFO|layer_utils.py:110] prior_b_input (InputLayer)                                        (None, 8)                                   0                                                                                         \n",
      "[root    |INFO|layer_utils.py:177] ________________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "[root    |INFO|layer_utils.py:110] mean_recon_error (Lambda)                                         (None,)                                     0                       real_image_input[0][0]                                            \n",
      "[root    |INFO|layer_utils.py:110]                                                                                                                                       decoder[3][0]                                                     \n",
      "[root    |INFO|layer_utils.py:177] ________________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "[root    |INFO|layer_utils.py:110] penalty_e (Lambda)                                                (None,)                                     0                       discriminator_e[4][0]                                             \n",
      "[root    |INFO|layer_utils.py:177] ________________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "[root    |INFO|layer_utils.py:110] penalty_b (Lambda)                                                (None,)                                     0                       prior_b_input[0][0]                                               \n",
      "[root    |INFO|layer_utils.py:110]                                                                                                                                       encoder_b_model[1][1]                                             \n",
      "[root    |INFO|layer_utils.py:177] ________________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "[root    |INFO|layer_utils.py:110] penalty_hsic (Lambda)                                             (None,)                                     0                       encoder_e_model[1][0]                                             \n",
      "[root    |INFO|layer_utils.py:110]                                                                                                                                       encoder_b_model[1][0]                                             \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[root    |INFO|layer_utils.py:175] ========================================================================================================================================================================================================\n",
      "[root    |INFO|layer_utils.py:188] Total params: 1,166,258\n",
      "[root    |INFO|layer_utils.py:189] Trainable params: 1,147,697\n",
      "[root    |INFO|layer_utils.py:190] Non-trainable params: 18,561\n",
      "[root    |INFO|layer_utils.py:191] ________________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "[root    |INFO|build_network.py:391] Loaded Discriminator model: GAN\n",
      "[root    |INFO|layer_utils.py:112] Model: \"GAN_model\"\n",
      "[root    |INFO|layer_utils.py:113] ________________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "[root    |INFO|layer_utils.py:110] Layer (type)                                                      Output Shape                                Param #                 Connected to                                                      \n",
      "[root    |INFO|layer_utils.py:115] ========================================================================================================================================================================================================\n",
      "[root    |INFO|layer_utils.py:110] real_image_input (InputLayer)                                     (None, 28, 28, 1)                           0                                                                                         \n",
      "[root    |INFO|layer_utils.py:177] ________________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "[root    |INFO|layer_utils.py:110] class_info_input (InputLayer)                                     (None, 1)                                   0                                                                                         \n",
      "[root    |INFO|layer_utils.py:177] ________________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "[root    |INFO|layer_utils.py:110] prior_e_input (InputLayer)                                        (None, 8)                                   0                                                                                         \n",
      "[root    |INFO|layer_utils.py:177] ________________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "[root    |INFO|layer_utils.py:110] encoder_e_model (Model)                                           (None, 8)                                   869360                  real_image_input[0][0]                                            \n",
      "[root    |INFO|layer_utils.py:110]                                                                                                                                       class_info_input[0][0]                                            \n",
      "[root    |INFO|layer_utils.py:177] ________________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "[root    |INFO|layer_utils.py:110] discriminator_e (Model)                                           (None, 1)                                   17281                   prior_e_input[0][0]                                               \n",
      "[root    |INFO|layer_utils.py:110]                                                                                                                                       encoder_e_model[1][0]                                             \n",
      "[root    |INFO|layer_utils.py:177] ________________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "[root    |INFO|layer_utils.py:110] mlp_concat (Concatenate)                                          (None, 2)                                   0                       discriminator_e[3][0]                                             \n",
      "[root    |INFO|layer_utils.py:110]                                                                                                                                       discriminator_e[4][0]                                             \n",
      "[root    |INFO|layer_utils.py:175] ========================================================================================================================================================================================================\n",
      "[root    |INFO|layer_utils.py:188] Total params: 886,641\n",
      "[root    |INFO|layer_utils.py:189] Trainable params: 868,304\n",
      "[root    |INFO|layer_utils.py:190] Non-trainable params: 18,337\n",
      "[root    |INFO|layer_utils.py:191] ________________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "[root    |INFO|<ipython-input-5-5e008ad04da6>:26] -----------------------------------------------------------------\n",
      "[root    |INFO|<ipython-input-5-5e008ad04da6>:28] Construct training data sampler\n",
      "[root    |INFO|samplers.py:109] -------------------------------------------------\n",
      "[root    |INFO|samplers.py:110] Images per Class\n",
      "[root    |INFO|samplers.py:111] \n",
      "7    5834\n",
      "3    5691\n",
      "9    5580\n",
      "0    5545\n",
      "4    5497\n",
      "8    5412\n",
      "5    5064\n",
      "1     628\n",
      "2     563\n",
      "6     543\n",
      "dtype: int64\n",
      "[root    |INFO|samplers.py:112] -------------------------------------------------\n",
      "[root    |INFO|samplers.py:113] Summary\n",
      "[root    |INFO|samplers.py:114] \n",
      "count      10.000000\n",
      "mean     4035.700000\n",
      "std      2394.316606\n",
      "min       543.000000\n",
      "25%      1737.000000\n",
      "50%      5454.500000\n",
      "75%      5571.250000\n",
      "max      5834.000000\n",
      "dtype: float64\n",
      "[root    |INFO|samplers.py:115] -------------------------------------------------\n",
      "[root    |INFO|<ipython-input-5-5e008ad04da6>:33] Construct test data sampler\n",
      "[root    |INFO|samplers.py:109] -------------------------------------------------\n",
      "[root    |INFO|samplers.py:110] Images per Class\n",
      "[root    |INFO|samplers.py:111] \n",
      "1    1596\n",
      "7    1459\n",
      "3    1450\n",
      "8    1413\n",
      "2    1403\n",
      "9    1378\n",
      "6    1367\n",
      "0    1358\n",
      "4    1327\n",
      "5    1249\n",
      "dtype: int64\n",
      "[root    |INFO|samplers.py:112] -------------------------------------------------\n",
      "[root    |INFO|samplers.py:113] Summary\n",
      "[root    |INFO|samplers.py:114] \n",
      "count      10.000000\n",
      "mean     1400.000000\n",
      "std        91.919047\n",
      "min      1249.000000\n",
      "25%      1360.250000\n",
      "50%      1390.500000\n",
      "75%      1440.750000\n",
      "max      1596.000000\n",
      "dtype: float64\n",
      "[root    |INFO|samplers.py:115] -------------------------------------------------\n",
      "[root    |INFO|<ipython-input-5-5e008ad04da6>:51] ------------------ 0 repeat ------------------------------------------------------\n",
      "[root    |INFO|<ipython-input-5-5e008ad04da6>:59] -------------------------------------------------\n",
      "[root    |INFO|<ipython-input-5-5e008ad04da6>:60] Images per Class\n",
      "[root    |INFO|<ipython-input-5-5e008ad04da6>:61] \n",
      "1    120\n",
      "0    114\n",
      "6    106\n",
      "9    103\n",
      "7     98\n",
      "3     98\n",
      "4     94\n",
      "2     91\n",
      "8     90\n",
      "5     86\n",
      "dtype: int64\n",
      "[root    |INFO|<ipython-input-5-5e008ad04da6>:62] -------------------------------------------------\n",
      "[root    |INFO|<ipython-input-5-5e008ad04da6>:63] Summary\n",
      "[root    |INFO|<ipython-input-5-5e008ad04da6>:64] \n",
      "count     10.00000\n",
      "mean     100.00000\n",
      "std       10.86278\n",
      "min       86.00000\n",
      "25%       91.75000\n",
      "50%       98.00000\n",
      "75%      105.25000\n",
      "max      120.00000\n",
      "dtype: float64\n",
      "[root    |INFO|<ipython-input-5-5e008ad04da6>:65] -------------------------------------------------\n",
      "[root    |INFO|<ipython-input-5-5e008ad04da6>:160] {'original_accuracy': 0.996999979019165, 'accuracy': 0.9350000023841858, 'one_shot_accuracy': 0.9390000104904175, 'sharpness_original': 0.07174386, 'sharpness_gen': 0.03747905, 'original_ssim_mean': 0.23559491, 'gen_ssim_mean': 0.3259979, 'sharpness_one_shot_gen': 0.03496425, 'one_shot_gen_ssim_mean': 0.27029794}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[root    |INFO|<ipython-input-5-5e008ad04da6>:51] ------------------ 1 repeat ------------------------------------------------------\n",
      "[root    |INFO|<ipython-input-5-5e008ad04da6>:59] -------------------------------------------------\n",
      "[root    |INFO|<ipython-input-5-5e008ad04da6>:60] Images per Class\n",
      "[root    |INFO|<ipython-input-5-5e008ad04da6>:61] \n",
      "1    119\n",
      "4    118\n",
      "3    112\n",
      "2    108\n",
      "8    100\n",
      "9     97\n",
      "6     91\n",
      "5     86\n",
      "7     85\n",
      "0     84\n",
      "dtype: int64\n",
      "[root    |INFO|<ipython-input-5-5e008ad04da6>:62] -------------------------------------------------\n",
      "[root    |INFO|<ipython-input-5-5e008ad04da6>:63] Summary\n",
      "[root    |INFO|<ipython-input-5-5e008ad04da6>:64] \n",
      "count     10.000000\n",
      "mean     100.000000\n",
      "std       13.581033\n",
      "min       84.000000\n",
      "25%       87.250000\n",
      "50%       98.500000\n",
      "75%      111.000000\n",
      "max      119.000000\n",
      "dtype: float64\n",
      "[root    |INFO|<ipython-input-5-5e008ad04da6>:65] -------------------------------------------------\n",
      "[root    |INFO|<ipython-input-5-5e008ad04da6>:160] {'original_accuracy': 0.9950000047683716, 'accuracy': 0.9380000233650208, 'one_shot_accuracy': 0.9380000233650208, 'sharpness_original': 0.07814332, 'sharpness_gen': 0.0375026, 'original_ssim_mean': 0.22050305, 'gen_ssim_mean': 0.25569385, 'sharpness_one_shot_gen': 0.03703915, 'one_shot_gen_ssim_mean': 0.22780125}\n",
      "[root    |INFO|<ipython-input-5-5e008ad04da6>:51] ------------------ 2 repeat ------------------------------------------------------\n",
      "[root    |INFO|<ipython-input-5-5e008ad04da6>:59] -------------------------------------------------\n",
      "[root    |INFO|<ipython-input-5-5e008ad04da6>:60] Images per Class\n",
      "[root    |INFO|<ipython-input-5-5e008ad04da6>:61] \n",
      "1    122\n",
      "0    120\n",
      "2    110\n",
      "8    106\n",
      "3    103\n",
      "9     94\n",
      "5     91\n",
      "7     88\n",
      "6     87\n",
      "4     79\n",
      "dtype: int64\n",
      "[root    |INFO|<ipython-input-5-5e008ad04da6>:62] -------------------------------------------------\n",
      "[root    |INFO|<ipython-input-5-5e008ad04da6>:63] Summary\n",
      "[root    |INFO|<ipython-input-5-5e008ad04da6>:64] \n",
      "count     10.000000\n",
      "mean     100.000000\n",
      "std       14.529663\n",
      "min       79.000000\n",
      "25%       88.750000\n",
      "50%       98.500000\n",
      "75%      109.000000\n",
      "max      122.000000\n",
      "dtype: float64\n",
      "[root    |INFO|<ipython-input-5-5e008ad04da6>:65] -------------------------------------------------\n",
      "[root    |INFO|<ipython-input-5-5e008ad04da6>:160] {'original_accuracy': 0.9959999918937683, 'accuracy': 0.9210000038146973, 'one_shot_accuracy': 0.9169999957084656, 'sharpness_original': 0.081489645, 'sharpness_gen': 0.031227801, 'original_ssim_mean': 0.23194185, 'gen_ssim_mean': 0.29031008, 'sharpness_one_shot_gen': 0.03306756, 'one_shot_gen_ssim_mean': 0.27659974}\n",
      "[root    |INFO|<ipython-input-5-5e008ad04da6>:51] ------------------ 3 repeat ------------------------------------------------------\n",
      "[root    |INFO|<ipython-input-5-5e008ad04da6>:59] -------------------------------------------------\n",
      "[root    |INFO|<ipython-input-5-5e008ad04da6>:60] Images per Class\n",
      "[root    |INFO|<ipython-input-5-5e008ad04da6>:61] \n",
      "3    124\n",
      "1    120\n",
      "7    107\n",
      "8    101\n",
      "2    101\n",
      "6     98\n",
      "9     92\n",
      "4     91\n",
      "0     90\n",
      "5     76\n",
      "dtype: int64\n",
      "[root    |INFO|<ipython-input-5-5e008ad04da6>:62] -------------------------------------------------\n",
      "[root    |INFO|<ipython-input-5-5e008ad04da6>:63] Summary\n",
      "[root    |INFO|<ipython-input-5-5e008ad04da6>:64] \n",
      "count     10.000000\n",
      "mean     100.000000\n",
      "std       14.344957\n",
      "min       76.000000\n",
      "25%       91.250000\n",
      "50%       99.500000\n",
      "75%      105.500000\n",
      "max      124.000000\n",
      "dtype: float64\n",
      "[root    |INFO|<ipython-input-5-5e008ad04da6>:65] -------------------------------------------------\n",
      "[root    |INFO|<ipython-input-5-5e008ad04da6>:160] {'original_accuracy': 0.9929999709129333, 'accuracy': 0.9419999718666077, 'one_shot_accuracy': 0.9319999814033508, 'sharpness_original': 0.0659625, 'sharpness_gen': 0.040497784, 'original_ssim_mean': 0.23286426, 'gen_ssim_mean': 0.2573741, 'sharpness_one_shot_gen': 0.038103368, 'one_shot_gen_ssim_mean': 0.25030166}\n",
      "[root    |INFO|<ipython-input-5-5e008ad04da6>:51] ------------------ 4 repeat ------------------------------------------------------\n",
      "[root    |INFO|<ipython-input-5-5e008ad04da6>:59] -------------------------------------------------\n",
      "[root    |INFO|<ipython-input-5-5e008ad04da6>:60] Images per Class\n",
      "[root    |INFO|<ipython-input-5-5e008ad04da6>:61] \n",
      "8    111\n",
      "6    111\n",
      "2    104\n",
      "3    103\n",
      "1    102\n",
      "0    102\n",
      "7    100\n",
      "4     94\n",
      "9     87\n",
      "5     86\n",
      "dtype: int64\n",
      "[root    |INFO|<ipython-input-5-5e008ad04da6>:62] -------------------------------------------------\n",
      "[root    |INFO|<ipython-input-5-5e008ad04da6>:63] Summary\n",
      "[root    |INFO|<ipython-input-5-5e008ad04da6>:64] \n",
      "count     10.000000\n",
      "mean     100.000000\n",
      "std        8.666667\n",
      "min       86.000000\n",
      "25%       95.500000\n",
      "50%      102.000000\n",
      "75%      103.750000\n",
      "max      111.000000\n",
      "dtype: float64\n",
      "[root    |INFO|<ipython-input-5-5e008ad04da6>:65] -------------------------------------------------\n",
      "[root    |INFO|<ipython-input-5-5e008ad04da6>:160] {'original_accuracy': 0.9959999918937683, 'accuracy': 0.9240000247955322, 'one_shot_accuracy': 0.7879999876022339, 'sharpness_original': 0.08105342, 'sharpness_gen': 0.030195182, 'original_ssim_mean': 0.23546045, 'gen_ssim_mean': 0.27123925, 'sharpness_one_shot_gen': 0.025511704, 'one_shot_gen_ssim_mean': 0.25609463}\n",
      "[root    |INFO|<ipython-input-5-5e008ad04da6>:51] ------------------ 5 repeat ------------------------------------------------------\n",
      "[root    |INFO|<ipython-input-5-5e008ad04da6>:59] -------------------------------------------------\n",
      "[root    |INFO|<ipython-input-5-5e008ad04da6>:60] Images per Class\n",
      "[root    |INFO|<ipython-input-5-5e008ad04da6>:61] \n",
      "1    109\n",
      "9    108\n",
      "2    108\n",
      "7    101\n",
      "3    100\n",
      "0     99\n",
      "8     96\n",
      "6     94\n",
      "4     94\n",
      "5     91\n",
      "dtype: int64\n",
      "[root    |INFO|<ipython-input-5-5e008ad04da6>:62] -------------------------------------------------\n",
      "[root    |INFO|<ipython-input-5-5e008ad04da6>:63] Summary\n",
      "[root    |INFO|<ipython-input-5-5e008ad04da6>:64] \n",
      "count     10.000000\n",
      "mean     100.000000\n",
      "std        6.497863\n",
      "min       91.000000\n",
      "25%       94.500000\n",
      "50%       99.500000\n",
      "75%      106.250000\n",
      "max      109.000000\n",
      "dtype: float64\n",
      "[root    |INFO|<ipython-input-5-5e008ad04da6>:65] -------------------------------------------------\n",
      "[root    |INFO|<ipython-input-5-5e008ad04da6>:160] {'original_accuracy': 0.9919999837875366, 'accuracy': 0.9440000057220459, 'one_shot_accuracy': 0.9369999766349792, 'sharpness_original': 0.07814332, 'sharpness_gen': 0.029074583, 'original_ssim_mean': 0.23925492, 'gen_ssim_mean': 0.27516103, 'sharpness_one_shot_gen': 0.023672888, 'one_shot_gen_ssim_mean': 0.30979693}\n",
      "[root    |INFO|<ipython-input-5-5e008ad04da6>:51] ------------------ 6 repeat ------------------------------------------------------\n",
      "[root    |INFO|<ipython-input-5-5e008ad04da6>:59] -------------------------------------------------\n",
      "[root    |INFO|<ipython-input-5-5e008ad04da6>:60] Images per Class\n",
      "[root    |INFO|<ipython-input-5-5e008ad04da6>:61] \n",
      "1    121\n",
      "0    114\n",
      "8    110\n",
      "6    101\n",
      "3     99\n",
      "2     98\n",
      "7     95\n",
      "9     93\n",
      "5     87\n",
      "4     82\n",
      "dtype: int64\n",
      "[root    |INFO|<ipython-input-5-5e008ad04da6>:62] -------------------------------------------------\n",
      "[root    |INFO|<ipython-input-5-5e008ad04da6>:63] Summary\n",
      "[root    |INFO|<ipython-input-5-5e008ad04da6>:64] \n",
      "count     10.000000\n",
      "mean     100.000000\n",
      "std       12.064641\n",
      "min       82.000000\n",
      "25%       93.500000\n",
      "50%       98.500000\n",
      "75%      107.750000\n",
      "max      121.000000\n",
      "dtype: float64\n",
      "[root    |INFO|<ipython-input-5-5e008ad04da6>:65] -------------------------------------------------\n",
      "[root    |INFO|<ipython-input-5-5e008ad04da6>:160] {'original_accuracy': 0.9919999837875366, 'accuracy': 0.9490000009536743, 'one_shot_accuracy': 0.8939999938011169, 'sharpness_original': 0.069483906, 'sharpness_gen': 0.034656186, 'original_ssim_mean': 0.23478723, 'gen_ssim_mean': 0.23966213, 'sharpness_one_shot_gen': 0.032431364, 'one_shot_gen_ssim_mean': 0.28678158}\n",
      "[root    |INFO|<ipython-input-5-5e008ad04da6>:51] ------------------ 7 repeat ------------------------------------------------------\n",
      "[root    |INFO|<ipython-input-5-5e008ad04da6>:59] -------------------------------------------------\n",
      "[root    |INFO|<ipython-input-5-5e008ad04da6>:60] Images per Class\n",
      "[root    |INFO|<ipython-input-5-5e008ad04da6>:61] \n",
      "1    113\n",
      "3    105\n",
      "7    103\n",
      "0    102\n",
      "9     99\n",
      "2     99\n",
      "8     97\n",
      "6     97\n",
      "5     96\n",
      "4     89\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[root    |INFO|<ipython-input-5-5e008ad04da6>:62] -------------------------------------------------\n",
      "[root    |INFO|<ipython-input-5-5e008ad04da6>:63] Summary\n",
      "[root    |INFO|<ipython-input-5-5e008ad04da6>:64] \n",
      "count     10.000000\n",
      "mean     100.000000\n",
      "std        6.359595\n",
      "min       89.000000\n",
      "25%       97.000000\n",
      "50%       99.000000\n",
      "75%      102.750000\n",
      "max      113.000000\n",
      "dtype: float64\n",
      "[root    |INFO|<ipython-input-5-5e008ad04da6>:65] -------------------------------------------------\n",
      "[root    |INFO|<ipython-input-5-5e008ad04da6>:160] {'original_accuracy': 0.9919999837875366, 'accuracy': 0.9259999990463257, 'one_shot_accuracy': 0.8450000286102295, 'sharpness_original': 0.08340762, 'sharpness_gen': 0.023462048, 'original_ssim_mean': 0.22253576, 'gen_ssim_mean': 0.23538718, 'sharpness_one_shot_gen': 0.030271258, 'one_shot_gen_ssim_mean': 0.2813709}\n",
      "[root    |INFO|<ipython-input-5-5e008ad04da6>:51] ------------------ 8 repeat ------------------------------------------------------\n",
      "[root    |INFO|<ipython-input-5-5e008ad04da6>:59] -------------------------------------------------\n",
      "[root    |INFO|<ipython-input-5-5e008ad04da6>:60] Images per Class\n",
      "[root    |INFO|<ipython-input-5-5e008ad04da6>:61] \n",
      "1    137\n",
      "7    115\n",
      "4    112\n",
      "8     95\n",
      "3     94\n",
      "9     93\n",
      "0     93\n",
      "5     91\n",
      "2     91\n",
      "6     79\n",
      "dtype: int64\n",
      "[root    |INFO|<ipython-input-5-5e008ad04da6>:62] -------------------------------------------------\n",
      "[root    |INFO|<ipython-input-5-5e008ad04da6>:63] Summary\n",
      "[root    |INFO|<ipython-input-5-5e008ad04da6>:64] \n",
      "count     10.000000\n",
      "mean     100.000000\n",
      "std       16.666667\n",
      "min       79.000000\n",
      "25%       91.500000\n",
      "50%       93.500000\n",
      "75%      107.750000\n",
      "max      137.000000\n",
      "dtype: float64\n",
      "[root    |INFO|<ipython-input-5-5e008ad04da6>:65] -------------------------------------------------\n",
      "[root    |INFO|<ipython-input-5-5e008ad04da6>:160] {'original_accuracy': 0.996999979019165, 'accuracy': 0.9440000057220459, 'one_shot_accuracy': 0.9369999766349792, 'sharpness_original': 0.07415133, 'sharpness_gen': 0.028228989, 'original_ssim_mean': 0.23280188, 'gen_ssim_mean': 0.2951513, 'sharpness_one_shot_gen': 0.029274564, 'one_shot_gen_ssim_mean': 0.28776017}\n",
      "[root    |INFO|<ipython-input-5-5e008ad04da6>:51] ------------------ 9 repeat ------------------------------------------------------\n",
      "[root    |INFO|<ipython-input-5-5e008ad04da6>:59] -------------------------------------------------\n",
      "[root    |INFO|<ipython-input-5-5e008ad04da6>:60] Images per Class\n",
      "[root    |INFO|<ipython-input-5-5e008ad04da6>:61] \n",
      "1    112\n",
      "9    111\n",
      "2    107\n",
      "6    106\n",
      "3    106\n",
      "8    101\n",
      "7     96\n",
      "0     93\n",
      "4     87\n",
      "5     81\n",
      "dtype: int64\n",
      "[root    |INFO|<ipython-input-5-5e008ad04da6>:62] -------------------------------------------------\n",
      "[root    |INFO|<ipython-input-5-5e008ad04da6>:63] Summary\n",
      "[root    |INFO|<ipython-input-5-5e008ad04da6>:64] \n",
      "count     10.000000\n",
      "mean     100.000000\n",
      "std       10.445626\n",
      "min       81.000000\n",
      "25%       93.750000\n",
      "50%      103.500000\n",
      "75%      106.750000\n",
      "max      112.000000\n",
      "dtype: float64\n",
      "[root    |INFO|<ipython-input-5-5e008ad04da6>:65] -------------------------------------------------\n",
      "[root    |INFO|<ipython-input-5-5e008ad04da6>:160] {'original_accuracy': 0.9950000047683716, 'accuracy': 0.9350000023841858, 'one_shot_accuracy': 0.7950000166893005, 'sharpness_original': 0.069483906, 'sharpness_gen': 0.033226207, 'original_ssim_mean': 0.21675503, 'gen_ssim_mean': 0.24712443, 'sharpness_one_shot_gen': 0.034932308, 'one_shot_gen_ssim_mean': 0.28710684}\n",
      "[root    |INFO|<ipython-input-5-5e008ad04da6>:175] -----------------------------------------------------------------\n",
      "[root    |INFO|<ipython-input-5-5e008ad04da6>:176] Results of PSOAE\n",
      "[root    |INFO|<ipython-input-5-5e008ad04da6>:177] -----------------------------------------------------------------\n",
      "[root    |INFO|<ipython-input-5-5e008ad04da6>:178] Original accuracy: 0.994 (\\pm 0.002)\n",
      "[root    |INFO|<ipython-input-5-5e008ad04da6>:179] Original_ssim_mean: 0.230 (\\pm 0.007)\n",
      "[root    |INFO|<ipython-input-5-5e008ad04da6>:180] Original_sharpness: 0.075 (\\pm 0.006)\n",
      "[root    |INFO|<ipython-input-5-5e008ad04da6>:182] Accuracy: 0.936 (\\pm 0.009)\n",
      "[root    |INFO|<ipython-input-5-5e008ad04da6>:183] Ssim_mean: 0.269 (\\pm 0.027)\n",
      "[root    |INFO|<ipython-input-5-5e008ad04da6>:184] Sharpness: 0.033 (\\pm 0.005)\n",
      "[root    |INFO|<ipython-input-5-5e008ad04da6>:187] One-shot Accuracy: 0.892 (\\pm 0.057)\n",
      "[root    |INFO|<ipython-input-5-5e008ad04da6>:188] One-shot Ssim_mean: 0.273 (\\pm 0.022)\n",
      "[root    |INFO|<ipython-input-5-5e008ad04da6>:189] One-shot Sharpness: 0.032 (\\pm 0.005)\n",
      "[root    |INFO|<ipython-input-5-5e008ad04da6>:215] -----------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model_path = 'mnist_pretrained/mnist_imbalance_psoae'\n",
    "model_aka = 'PSOAE'\n",
    "path_info_config = \"configurations/mnist/psoae_path_info.cfg\"\n",
    "network_info_config = \"configurations/mnist/psoae_network_info.cfg\"\n",
    "feature_b = False\n",
    "\n",
    "get_numerics(model_path, model_aka, path_info_config, network_info_config, feature_b)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
